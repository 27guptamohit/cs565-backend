{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from dotenv import dotenv_values\n",
    "import json\n",
    "import os\n",
    "from music_symbol import MusicSymbol\n",
    "from pathlib import Path\n",
    "from response_metrics import ResponseMetrics\n",
    "import sys\n",
    "\n",
    "# Importing from parent directory\n",
    "curr_file = Path(os.path.abspath('')).resolve()\n",
    "sys.path.append(str(curr_file.parent))\n",
    "from scripts.backup_data import main as load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from backups\n"
     ]
    }
   ],
   "source": [
    "backup_prefix = \"testing/20230504-145732\"\n",
    "# Set to None to pull from the database live\n",
    "# backup_prefix = None\n",
    "\n",
    "if backup_prefix is None:\n",
    "    config = dotenv_values(\"../.env\")\n",
    "    ENDPOINT = config[\"ENDPOINT\"]\n",
    "\n",
    "    print(\"Grabbing data from DB\")\n",
    "    users_data, sheets_data, measures_data = load_data(ENDPOINT, \"../backups/live\")\n",
    "else:\n",
    "    print(\"Loading from backups\")\n",
    "    with open(f\"../backups/{backup_prefix}_users_backup.json\", \"r\") as file:\n",
    "        users_data = json.load(file)\n",
    "\n",
    "    with open(f\"../backups/{backup_prefix}_sheets_backup.json\", \"r\") as file:\n",
    "        sheets_data = json.load(file)\n",
    "\n",
    "    with open(f\"../backups/{backup_prefix}_measures_backup.json\", \"r\") as file:\n",
    "        measures_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Users: 43\n",
      "# Sheets: 3\n",
      "# Measures: 48\n"
     ]
    }
   ],
   "source": [
    "print(f\"# Users: {len(users_data)}\")\n",
    "print(f\"# Sheets: {len(sheets_data)}\")\n",
    "print(f\"# Measures: {len(measures_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Responses: 183\n"
     ]
    }
   ],
   "source": [
    "responses = 0\n",
    "for measure in measures_data:\n",
    "    responses += len(measure[\"responses\"])\n",
    "\n",
    "print(f\"# Responses: {responses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: 10, 4: 37, 5: 1}\n"
     ]
    }
   ],
   "source": [
    "response_count = dict()\n",
    "for measure in measures_data:\n",
    "    num_responses = len(measure[\"responses\"])\n",
    "    if num_responses not in response_count:\n",
    "        response_count[num_responses] = 0\n",
    "    \n",
    "    response_count[num_responses] += 1\n",
    "\n",
    "print(response_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_data: dict[str, ResponseMetrics] = {}\n",
    "crowdsourced_response_data: dict[str, ResponseMetrics] = {}\n",
    "crowdsourced_agreement_count: int = 0\n",
    "\n",
    "for measure in measures_data:\n",
    "    gold_symbols: list[MusicSymbol] = []\n",
    "    for symbol in measure[\"goldSymbols\"]:\n",
    "        gold_symbols.append(MusicSymbol(**symbol))\n",
    "    \n",
    "    while (len(gold_symbols) < 4):\n",
    "        gold_symbols.append(None)\n",
    "    \n",
    "    response_counter = Counter()\n",
    "\n",
    "    for response in measure[\"responses\"]:\n",
    "        response_id = response[\"_id\"]\n",
    "        user_symbols: list[MusicSymbol] = []\n",
    "        for symbol in response[\"symbols\"]:\n",
    "            user_symbols.append(MusicSymbol(**symbol))\n",
    "        \n",
    "        while (len(user_symbols) < 4):\n",
    "            user_symbols.append(None)\n",
    "\n",
    "        response_counter[tuple(user_symbols)] += 1\n",
    "    \n",
    "        response_data[response_id] = ResponseMetrics(user_symbols, gold_symbols)\n",
    "    \n",
    "    # no responses, skip\n",
    "    if len(response_counter) == 0:\n",
    "        continue\n",
    "\n",
    "    measure_id = measure[\"_id\"]\n",
    "    crowdsourced_symbols, primary_count = response_counter.most_common(1)[0]\n",
    "\n",
    "    if len(response_counter) >= 2:\n",
    "        # get the count of the second most frequent item\n",
    "        second_count = response_counter.most_common(2)[1][1]\n",
    "\n",
    "        # tie, no crowdsourced answer\n",
    "        if primary_count > second_count:\n",
    "            crowdsourced_agreement_count += 1\n",
    "    else:\n",
    "        crowdsourced_agreement_count += 1\n",
    "    \n",
    "    crowdsourced_response_data[measure_id] = ResponseMetrics(list(crowdsourced_symbols), gold_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_response_ids = []\n",
    "for measure in measures_data:\n",
    "    for response in measure[\"responses\"]:\n",
    "        all_response_ids.append(response[\"_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(response_metrics_map: dict[str, ResponseMetrics], key_group: list[str], title: str, units: str=\"responses\", print_results: bool=True):\n",
    "    symbol_num_match_count = 0\n",
    "    name_match_count = 0\n",
    "    pitch_match_count = 0\n",
    "    exact_match_count = 0\n",
    "    \n",
    "    pitch_count = 0\n",
    "    total_count = len(key_group)\n",
    "    for key in key_group:\n",
    "        if response_metrics_map[key].full_symbol_count_match():\n",
    "            symbol_num_match_count += 1\n",
    "\n",
    "        if response_metrics_map[key].full_name_match():\n",
    "            name_match_count += 1\n",
    "        \n",
    "        pitch_match = response_metrics_map[key].full_pitch_match()\n",
    "        if pitch_match is not None:\n",
    "            pitch_count += 1\n",
    "\n",
    "            if pitch_match:\n",
    "                pitch_match_count += 1\n",
    "        \n",
    "        if response_metrics_map[key].full_exact_match():\n",
    "            exact_match_count += 1\n",
    "    \n",
    "    symbol_num_match_accuracy = symbol_num_match_count / total_count\n",
    "    name_match_accuracy = name_match_count / total_count\n",
    "    pitch_match_accuracy = pitch_match_count / pitch_count\n",
    "    exact_match_accuracy = exact_match_count / total_count\n",
    "\n",
    "    if print_results:\n",
    "        print(title)\n",
    "        print(\"-\" * len(title))\n",
    "        print(f\"{total_count} {units}, {pitch_count} {units} with pitch content\")\n",
    "        print(f\"{'Symbol count accuracy:':<35} {symbol_num_match_count}/{total_count} {units} = {symbol_num_match_accuracy * 100:.4f}%\")\n",
    "        print(f\"{'Symbol identification accuracy:':<35} {name_match_count}/{total_count} {units} = {name_match_accuracy * 100:.4f}%\")\n",
    "        print(f\"{'Symbol pitch accuracy:':<35} {pitch_match_count}/{pitch_count} {units} = {pitch_match_accuracy * 100:.4f}%\")\n",
    "        print(f\"{'Symbol exact match accuracy:':<35} {exact_match_count}/{total_count} {units} = {exact_match_accuracy * 100:.4f}%\")\n",
    "    \n",
    "    return symbol_num_match_accuracy, name_match_accuracy, pitch_match_accuracy, exact_match_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All response data metrics\n",
      "-------------------------\n",
      "183 responses, 156 responses with pitch content\n",
      "Symbol count accuracy:              177/183 responses = 96.7213%\n",
      "Symbol identification accuracy:     174/183 responses = 95.0820%\n",
      "Symbol pitch accuracy:              138/156 responses = 88.4615%\n",
      "Symbol exact match accuracy:        162/183 responses = 88.5246%\n"
     ]
    }
   ],
   "source": [
    "calculate_statistics(response_data, all_response_ids, title=\"All response data metrics\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crowdsourced response data metrics\n",
      "----------------------------------\n",
      "48 measures, 41 measures with pitch content\n",
      "Symbol count accuracy:              48/48 measures = 100.0000%\n",
      "Symbol identification accuracy:     48/48 measures = 100.0000%\n",
      "Symbol pitch accuracy:              40/41 measures = 97.5610%\n",
      "Symbol exact match accuracy:        47/48 measures = 97.9167%\n",
      "Crowd conclusively agreed on:       46/48 measures = 95.8333%\n"
     ]
    }
   ],
   "source": [
    "calculate_statistics(crowdsourced_response_data, crowdsourced_response_data.keys(), title=\"Crowdsourced response data metrics\", units=\"measures\")\n",
    "print(f\"{'Crowd conclusively agreed on:':<35} {crowdsourced_agreement_count}/{len(crowdsourced_response_data)} measures = {crowdsourced_agreement_count / len(crowdsourced_response_data) * 100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backend-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
